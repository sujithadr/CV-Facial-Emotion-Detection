# Facial Emotion Detection using YOLOv11

> ğŸ§ª Object Detection-based Emotion Recognition | ğŸ¯ YOLOv11 | ğŸ‹ï¸ Training + ğŸ“¸ Real-time Inference

## ğŸ” Overview

This project demonstrates a complete pipeline for **facial emotion detection** using **YOLOv11**, treating emotion recognition as an **object detection** task.

While traditional systems often rely on facial embeddings (like FaceNet or DeepFace), this project explores YOLOv11 as an experimental alternative â€” capable of both training and running real-time webcam inference.

---

## ğŸ“¦ Key Features

- âš™ï¸ Environment setup via Jupyter notebook
- ğŸ“ Dataset preparation for training
- ğŸ§  YOLOv11 model training
- ğŸ’¾ Model export and storage
- ğŸ¥ Real-time webcam detection using the trained model

---

## ğŸ› ï¸ Repository Structure

```
CV-Facial-Emotion-Detection/
â”‚
â”œâ”€â”€ Facial_Emotion_Detection_using_Yolo11.ipynb   # Environment setup + training pipeline
â”œâ”€â”€ inference_app/
â”‚   â””â”€â”€ webcam_emotion_detector.py                # Webcam-based real-time emotion detection
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best.pt                                   # Trained YOLOv11 model (downloaded/exported)
â”œâ”€â”€ requirements.txt                              # Runtime-only dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/sujithadr/CV-Facial-Emotion-Detection.git
cd CV-Facial-Emotion-Detection
```

---

## ğŸ§ª Model Training (Optional)

If you'd like to train your own model:

### Step 1: Install training dependencies manually or via notebook cells

use colab to train for the GPU support

### Step 2: Run the notebook

```bash
jupyter notebook Facial_Emotion_Detection_using_Yolo11.ipynb
```

The notebook will guide you through:

- Environment setup (YOLO repo + dependencies)
- Dataset loading (e.g., FER2013)
- Training configuration
- Model training and export (`best.pt`)

---

## ğŸ¥ Real-time Emotion Detection (Inference)

Once training is complete or if you're using a pre-trained model:

### Step 1: Install runtime dependencies

```bash
pip install -r requirements.txt
```

### Step 2: Run the webcam detector

```bash
python inference_app/webcam_emotion_detector.py
```

This script:
- Loads the trained model from `models/best.pt`
- Opens the webcam
- Predicts and displays facial emotions in real time

---

## ğŸ“Œ Notes

- This is an experimental project for educational use.
- Facial embeddings are generally preferred for production-level applications.
- The training notebook can be skipped if using a pre-trained model.

---

## ğŸ“š References

- ğŸ”— [YOLOv11 GitHub](https://github.com/WongKinYiu/yolov11)
- ğŸ“Š [FER2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)
- ğŸ“· [OpenCV](https://opencv.org/)

---

## ğŸ¤ Contributions

Contributions are welcome! Feel free to fork the repo, make improvements, and open a pull request.

---

## ğŸ§¾ License

Licensed under the [MIT License](LICENSE).  By Sujith Somanunnithan

---

## ğŸ”— Repository

GitHub: [CV-Facial-Emotion-Detection](https://github.com/sujithadr/CV-Facial-Emotion-Detection.git)
